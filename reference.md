Superhuman has] identified a feature that provides value to some of their customers . . . and they’ve trampled the privacy of every single person they send email to in order to achieve that.

we focused only on the needs of our customers. We did not consider potential bad actors

had argued that the inclusion of the read-receipts feature would have knock-on effects. We need to consider not only our customers, but also future users, the people they communicate with, and the Internet at large

All the same, recipients of e-mails sent with the feature enabled still won’t be able to opt out, and won’t be alerted to the inclusion of a tracking pixel

Since the 2016 election, though, tech coverage has grown more skeptical, investigative, and serious—a shift from treating Silicon Valley as a novelty to seeing it as the power center it has become

Variations on the sentiment that “it’s easier to criticize than create” proliferate. Feedback is internalized personally rather than structurally. There is a deepening sense of victimhood.

In a professional context, pixel-tracking is a fairly benign tool; it can be used for content marketing, lead generation, or reëngagement. But it takes on a different sheen when it’s deployed for personal use. 

Like most software products, it is designed to prioritize the specific interests of its own users: in this case, knowledge workers, managers, executives, and entrepreneurs. —is an appealing time-saver. E-mail, for this audience, is a chore, or a field of opportunity, at least as much as it’s a medium for interpersonal communication. 

One might experience anxiety upon seeing that someone has read but not responded to a message; glimpsing a correspondent’s e-mail habits, one might enjoy an ambient sense of superiority or leverage. 

The real value of read statuses may just be a feeling: being privy to other people’s data, consensually or otherwise, can create a sense of power or control. There’s a certain satisfaction to surveillance. Data isn’t necessarily knowledge, but it can feel like it.

At issue, ultimately, is the ethical question of what makes software “good.

The qualities of good software include seamlessness, efficiency, speed, simplicity, and straightforward user-experience design. Failing to maximize these values may feel, for a software engineer, like driving a Ferrari below the speed limit—a violation of the spirit of the enterprise. 

the short-term satisfactions offered by software can upstage its longer-term implications. One of the challenges of ethical software design is that, in some respects, it asks developers and designers to work against themselves and to counteract what makes software so useful in the first place. 

 the final state of a shipped product is often the aggregation of a series of arbitrary choices made along the way, an accretion of guesswork, experimentation, and technical possibility. 

But technologies that are useful and morally permissible in that context may be harmful and unethical at the ordinary, human level. The question then is how and when to scale them back.

Email startup Superhuman ruffled some feathers this week thanks to a viral blog post by former Twitter vice president of design Mike Davidson detailing how one of the $30 a month service’s core features was actually a run-of-the-mill privacy-violating tracking pixel that transmits information about recipients, including geolocation, back to the sender every time an email containing it was opened.

Now that there’s been a considerable backlash against the firm, Superhuman says it’s canning one of those effective immediately, as well as changing others.

Tracking pixels are often criticized by data protection advocates because they collect comprehensive data about the user, mostly without knowledge of the user. As the tracking pixel cannot be seen with the naked eye, and the common user does not recognize the meaning of the small graphic even when it is visible, the tracking pixel involves a transfer of information without consent.

use of tracking pixels is beneficial for website operators, SEOs and email senders. This is because they can use the information generated to improve their online offers, make them more user-friendly, and adapt the offers to the most commonly used browser types and versions.
Even more advantageous is the fact that tracking pixels are more effective than cache in browsers: The access to a page is still counted. If JavaScript is used, more information can be collected. This includes the screen resolution, plugins used, support of certain technologies by the browser, etc. It therefore becomes possible to differentiate between users and bots, as well as create user profiles. The IP address, visits by a certain user, and the properties of this user can be used to create navigation paths. For web analysis, however, the tracking pixel generally just forms the basis. Advanced technologies are required which are only realizable by specialized service providers.
Tracking pixels can also be beneficial in the analysis of sent email newsletters, because they show the opening rates of certain emails or newsletters through the user statistics data. Together with A/B tests, successful campaigns can thus be determined. From the recipient’s point of view, this has the advantage that newsletters in the future can be designed to be more relevant and interesting.

The mainstreaming of digital vaccine passes could lead to more surveillance, privacy researchers cautioned.
Many developers said they had taken pains to make sure the passports do not cross privacy boundaries. 

officials said in January that data from the country’s coronavirus contact-tracing system had been used in a criminal investigation, even though leaders had initially said it would be used only for contact tracing.

Some business groups and companies that have adopted vaccine passes said the privacy concerns were valid but addressable.

The measures faced strong resistance from computer scientists, privacy groups and civil-liberty lawyers because the features represented the first technology that would allow a company to look at a person’s private data and report it to law enforcement authorities.

once the ability to sift through users’ private photos was out there, it would have been ripe for misuse. Governments, for example, could potentially lean on Apple’s technology to help track down dissidents.

great that they’re taking a moment to think things over,” but that he and other privacy coalitions would continue to plead with Apple to abandon its plan altogether.

Market researchers are willing to pay brokers for a huge array of data, from dating preferences to political leanings, household purchases to streaming favourites

So the choice was whether to keep mum, he said, or to publish the method so that data vendors can secure future data sets and prevent individuals from being re-identified. It’s always a dilemma

The consensus so far is to disclose. That is how you advance the field: Publish the code, publish the finding

The balance is tricky: Information that becomes completely anonymous also becomes less useful, particularly to scientists trying to reproduce the results of other studies. But every small bit that is retained in a database makes identification of individuals more possible.

The implications of this fundamental shift in the underlying philosophical framework regarding data privacy protection will be profound in the years and decades to come.

the European Union (EU) have long pursued a rights-based regime for protecting personal information. Historically this philosophy holds that data privacy is a fundamental human right. Individuals effectively own their personal information, and who can use it is a matter for them to decide.

Europeans had a “right to delist,” meaning that individuals, corporations and even government officials could request that material be removed from Google’s search results, if deemed “inaccurate, inadequate, irrelevant or excessive,” and not related to discourse regarding the public interest.

There is no “right to be forgotten” in the abstract; no law can ensure that, and no law can be limited to that. Instead, the “right” this aims to protect is the power to suppress speech — the power to force people (on pain of financial ruin) to stop talking about other people, when some government body decides that they should stop.”

The Texas attorney general filed a privacy lawsuit against Google on Thursday, accusing the internet company of collecting Texans’ facial and voice recognition information without their explicit consent.

Google’s indiscriminate collection of the personal information of Texans, including very sensitive information like biometric identifiers, will not be tolerated,

the products violated the rights of both users and nonusers, whose faces and voices were scanned or processed without their understanding or consent

But for the Court to outsource to Google complicated case-specific decisions about whether to publish or suppress something is wrong. Requiring Google to be a court of philosopher kings shows a real lack of understanding about how this will play out in reality.

It’s a pragmatic solution. This speed-bump approach gives people a chance to grow and get beyond these incidents in their pasts.
The Internet’s unregulated idyll seems to be coming to an end, at least in Europe. family brought suit against it and the two employees who leaked the photographs, on a variety of grounds, including negligence, infliction of emotional distress, and invasion of privacy. 

The breach, privacy experts say, underscores the delicate balance the cloud computing platforms have struck between security and efficiency.

The largest “clouds” are run by the likes of Amazon, Microsoft and Google, and store data on hard drives. While this increases the free flow of data, it also expands the potential of hackers to loot data.
The evolution of cloud security and data encryption is being driven by some of the industry’s top computer scientists, hired out of the world’s best scientific universities and the National Security Agency.

That new wrinkle — insider information — is a formidable challenge across the industry.
“Financial Institutions need to take all the normal precautions and now a new one, where an ex-employee of their cloud hosting provider could prove to be a threat,” Atlantic.net’s Mr. Puranik said. “They know the intricate details of the architecture and how to exploit the small nooks and crannies for any weaknesses.”
FBI took disruptive action against a Fancy Bear campaign known as “VPNFilter” which targeted routers and network storage devices with malware with destructive capabilities of “bricking” a device by deleting firmware and rendering the device unusable. That campaign especially targeted Ukraine, a favorite target of Fancy Bear.

Many companies now want to cohabit again with their remote employees. 
Many remote employees have discovered they're quite happy working remotely and eschewing the commute. And, well, the need to dress up and act as if they actually like their coworkers.

The goal of hacking is to manipulate digital devices in order to cause damage or corrupt operating systems. It also allows hackers to collect user information, steal sensitive information and documents or perform other disruptive data related activities.
While hackers can be both ethical and malicious, most fall within three main types of hacking. These three main varieties of hackers are authorized, unauthorized and grey-hat hackers. Each type has different intents and purposes for their exploits. Let's explore each of these types of hackers and how they operate.

Grey-hat hackers are individuals who exploit security vulnerabilities to spread public awareness that the vulnerability exists. While these hackers do not share the malicious intent commonly attributed to unauthorized hackers, they also don’t necessarily adhere to a code of ethics like authorized hackers.

Ethical hacking often involves many different facets of the information security field. This role requires a lot of knowledge and expertise, from coding and programming to penetration testing and risk assessment. There is a lot to learn within the ethical hacking career, but it’s a high-demand field that will only continue to grow the more technology is used in our world.

 Harvard University revealed that it had rescinded admissions offers to at least 10 students who shared offensive images within what they thought was a private Facebook group chat. The students posted memes and images that mocked minority groups, child abuse, sexual assault and the Holocaust, among other things.

Sharing videos, images and memes creates the opportunity for an instantaneous positive feedback loop that can perpetuate poor decision making.

Adults need to shift the conversation around teens’ social media use away from a fear of getting caught and more toward healthy socialization, effective self-regulation and overall safety. 

But such high-level monitoring runs the risk of breaching trust with teens at a crucial developmental time.

Another option is to help young social media users realize that their online and real-life experiences are more intertwined than they may think.

Some also point out that Facebook’s interests as a company often conflict with the safety of its users. That means you’re going to have a collision between what’s good for mental health and what’s good for profit.

But social media apps like Instagram exacerbate that problem for a segment of the population that is already prone to making these comparisons

[It] could just be that a system that encourages visual sharing unintentionally creates a prestige economy that is detrimental to the vulnerable

Potentially, if there was more diversity incorporated into those algorithms, it might be helpful

While social media may offer some benefits, there are ample indicators that social media can also pose a risk of harm to the mental health and well-being of children and adolescents.

With adolescence and childhood representing a critical stage in brain development that can make young people more vulnerable to harms from social media, the Surgeon General is issuing a call for urgent action by policymakers, technology companies, researchers, families, and young people alike to gain a better understanding of the full impact of social media use, maximize the benefits and minimize the harms of social media platforms, and create safer, healthier online environments to protect children. 

Children are exposed to harmful content on social media, ranging from violent and sexual content, to bullying and harassment. And for too many children, social media use is compromising their sleep and valuable in-person time with family and friends. We are in the middle of a national youth mental health crisis, and I am concerned that social media is an important driver of that crisis – one that we must urgently address.

Among the benefits, adolescents report that social media helps them feel more accepted (58%), like they have people who can support them through tough times (67%), like they have a place to show their creative side (71%), and more connected to what’s going on in their friends’ lives (80%).

However, social media use can be excessive and problematic for some children. Recent research shows that adolescents who spend more than three hours per day on social media face double the risk of experiencing poor mental health outcomes, such as symptoms of depression and anxiety. Social media may also perpetuate body dissatisfaction, disordered eating behaviors, social comparison, and low self-esteem, especially among adolescent girls. Studies have also shown a relationship between social media use and poor sleep quality, reduced sleep duration, sleep difficulties, and depression among youth. 

Policymakers can take steps to strengthen safety standards and limit access in ways that make social media safer for children of all ages, better protect children’s privacy, support digital and media literacy, and fund additional research.
Technology companies can better and more transparently assess the impact of their products on children, share data with independent researchers to increase our collective understanding of the impacts, make design and development decisions that prioritize safety and health – including protecting children’s privacy and better adhering to age minimums – and improve systems to provide effective and timely responses to complaints.
Parents and caregivers can make plans in their households such as establishing tech-free zones that better foster in-person relationships, teach kids about responsible online behavior and model that behavior, and report problematic content and activity.
Children and adolescents can adopt healthy practices like limiting time on platforms, blocking unwanted content, being careful about sharing personal information, and reaching out if they or a friend need help or see harassment or abuse on the platforms.
Researchers can further prioritize social media and youth mental health research that can support the establishment of standards and evaluation of best practices to support children’s health.

Information operations exploit information systems (like social media platforms) to manipulate audiences for strategic, political goals—in this case, one of the goals was to influence the U.S. election in 2016.

“bots” – pushing messages in a coordinated manner, an increasingly common practice to manipulate public opinion by creating the false impression that many people are talking about a particular subject. 

For example, BotSlayer could be used during a presidential debate to not only instantly detect when a candidate’s username or related hashtags are trending, but also automatically assign a “bot score” to indicate whether the surge appears related to bot activity. In business, BotSlayer could help organizations protect against reputational threats that rely on automated accounts to amplify messages. In journalism, the tool could be used to monitor against manipulation of reporting on trending topics, or warn the public against disinformation attacks.

The findings highlight a major challenge for efforts to accurately communicate the rapidly evolving science about the pandemic when false and ambiguous information can spread quickly, whether inadvertently or deliberately, through social media, polarized news sources and other outlets.

It is 100% the responsibility of the platform to protect its users from harmful content,
Simply prohibiting certain kinds of content isn't going to help people find good information, or make them feel more confident about what they're hearing from their medical providers
"I think we all have a collective responsibility," Jha said of combating misinformation about COVID. "The consequences of not getting this right — of spreading that misinformation — is literally tens of thousands of people dying unnecessarily."

The rise of “fake news” and the proliferation of doctored narratives that are spread by humans and bots online are challenging publishers and platforms. 

the quality and veracity of information online deteriorate due to the spread of unreliable, sometimes even dangerous, socially destabilizing ideas

The fake news ecosystem preys on some of our deepest human instincts: Respondents said humans’ primal quest for success and power – their “survival” instinct – will continue to degrade the online information environment in the next decade. They predicted that manipulative actors will use new digital tools to take advantage of humans’ inbred preference for comfort and convenience and their craving for the answers they find in reinforcing echo chambers.
Our brains are not wired to contend with the pace of technological change: These respondents said the rising speed, reach and efficiencies of the internet and emerging online applications will magnify these human tendencies and that technology-based solutions will not be able to overcome them. They predicted a future information landscape in which fake information crowds out reliable information. Some even foresaw a world in which widespread information scams and mass manipulation cause broad swathes of public to simply give up on being informed participants in civic life.

Technology can help fix these problems: These more hopeful experts said the rising speed, reach and efficiencies of the internet, apps and platforms can be harnessed to rein in fake news and misinformation campaigns. Some predicted better methods will arise to create and promote trusted, fact-based news sources.
It is also human nature to come together and fix problems: The hopeful experts in this canvassing took the view that people have always adapted to change and that this current wave of challenges will also be overcome. They noted that misinformation and bad actors have always existed but have eventually been marginalized by smart people and processes. They expect well-meaning actors will work together to find ways to enhance the information environment. They also believe better information literacy among citizens will enable people to judge the veracity of material content and eventually raise the tone of discourse.

Humans are by nature selfish, tribal, gullible convenience seekers who put the most trust in that which seems familiar
The respondents who supported this view noted that people’s actions – from consciously malevolent and power-seeking behaviors to seemingly more benign acts undertaken for comfort or convenience – will work to undermine a healthy information environment.

There is no market for the truth. The public isn’t motivated to seek out verified, vetted information. They are happy hearing what confirms their views. And people can gain more creating fake information (both monetary and in notoriety) than they can keeping it from occurring.”

 In existing economic, political and social systems, the powerful corporate and government leaders most able to improve the information environment profit most when it is in turmoil
A large number of respondents said the interests of the most highly motivated actors, including those in the worlds of business and politics, are generally not motivated to “fix” the proliferation of misinformation. Those players will be a key driver in the worsening of the information environment in the coming years and/or the lack of any serious attempts to effectively mitigate the problem.

 Human tendencies and infoglut drive people apart and make it harder for them to agree on “common knowledge.” That makes healthy debate difficult and destabilizes trust. The fading of news media contributes to the problem
Many respondents expressed concerns about how people’s struggles to find and apply accurate information contribute to a larger social and political problem: There is a growing deficit in commonly accepted facts or some sort of cultural “common ground.” Why has this happened? They cited several reasons:

Ignorance breeds frustration and ‘a growing fraction of the population has neither the skills nor the native intelligence to master growing complexity’

YouTube’s recommendation system determines what content should appear on a user’s home page and in the user’s “Up Next” sidebar, which appears next to videos that a user is currently watching. The Up Next feature autoplays recommended content unless a user turns the autoplay off.

YouTube is one of the largest video repositories on the internet, and many users incorrectly equate the site’s popularity with the credibility of its recommendation system. However, despite the fact that YouTube’s recommendation system is responsible for shaping how billions of individuals engage with content on the service, and influencing how they see the world, the company has provided relatively little transparency around how this system works.

This lack of transparency is concerning, as the company’s recommendation system has been found to suggest controversial and harmful videos, including those that promote extremist propaganda, conspiracy theories, and misinformation. 

According to a YouTube spokeswoman, in late 2016, the company adopted social responsibility as a core value for the company.82 During this time, the recommendation system was altered so it considered inputs such as how many times a video was shared, liked, and disliked. 83 These changes were introduced amidst growing pressure on internet platforms to be more proactive in their efforts to combat harmful content, such as extremist propaganda, disinformation and misinformation, and content unsafe for children.84 Recently, the company has provided more detail around this concept of responsibility, outlining that it consists of the four Rs of responsibility:85
•	Removing content that violates the platform’s Community Guidelines as quickly as possible
•	Raising up authoritative information sources, especially during breaking news moments
•	Reducing the spread of content that comes close to violating, but does not violate the platform’s Community Guidelines (known as borderline content)
•	Rewarding trusted creators
However, this comes with trade-offs: It is challenging to define authoritative sources across more subjective verticals, as these determinations are based on personal preference and taste.102
As described above, YouTube provides very little transparency and accountability around how its recommendation system is structured, how it operates, and how it makes decisions.118 Research has suggested that promoting awareness of the use of algorithmic tools and enabling users to control their own experiences on a platform are fundamental steps in building trust with users. This lack of transparency from YouTube therefore limits the agency users have over their own experiences.1

Although YouTube has stated that conspiracy theory videos make up less than 1 percent of all content on the platform, this is still a staggering amount of content, and the problem is compounded whenever the recommendation algorithm promotes this content.

In addition, YouTube has faced particular criticism for creating a “rabbit hole” effect, in which the algorithm delivers personalized recommendations that prompt users to consume harmful or radical content130 that they did not originally seek out.

former YouTube employee-turned-critic Guillaume Chaslot, have argued that it is in the company's business interest to promote such polarizing and fringe videos and channels, as they drive engagement and greater watch times. Further, critics such as Chaslot have suggested that the recommendation system is biased toward promoting divisive, sensational, and conspiratorial content,138 perhaps because the system has learned that such content is engaging.139 Given the vast number of users who consume recommended content, this raises significant concerns about the platform serving as a radicalization pipeline.140

This raises concerns that the company is placing profits over ensuring the company’s use of automated tools is responsible, transparent, and accountable.

As highlighted, YouTube does not provide significant transparency around how its recommendation system operates, thus limiting the agency users have over their personal YouTube experience. The company does, however, offer its users a limited set of controls over how this system shapes their platform experience.

Market dominance is, as such, not illegal under EU antitrust rules. However, dominant companies have a special responsibility not to abuse their powerful market position by restricting competition, either in the market where they are dominant or in separate markets.
Google has abused this market dominance by preventing rivals from competing in the online search advertising intermediation market.
Based on a broad range of evidence, the Commission found that Google's conduct harmed competition and consumers, and stifled innovation. Google's rivals were unable to grow and offer alternative online search advertising intermediation services to those of Google. As a result, owners of websites had limited options for monetizing space on these websites and were forced to rely almost solely on Google.
Google's practices covered over half the market by turnover throughout most of the period. Google's rivals were not able to compete on the merits, either because there was an outright prohibition for them to appear on publisher websites or because Google reserved for itself by far the most valuable commercial space on those websites, while at the same time controlling how rival search adverts could appear.
currently user-centred approaches do not consider the interests of a variety of other stakeholders—as opposed to just the receivers of a recommendation—in assessing the ethical impacts of a recommender system.
Specifying these parameter choices is highly dependent on the domain of application and the level of abstraction [LoAs, see (Floridi 2016)]Footnote1 from which the problem is considered (Jannach et al. 2012). Typically, the literature implements three LoAs: catalogue-based, decision support, and multi-stakeholder environment. Let us consider each of these in turn.


The value of some consequences is often measured in terms of the utility they contain. So, it is reasonable to assume that any aspect of a RS that could impact negatively the utility of any of its stakeholders, or risk imposing such negative impacts, constitutes a feature that is ethically relevant.
 In the case of RS, for example, the risks may involve exposing users to undue privacy violations by external actors, or the exposure to potentially irrelevant or damaging content. Exposure to risks of these sorts can constitute a wrong, even if no adverse consequences actually materialize

Typically, the debate focuses on the fact that these sites are owned by private companies. One side argues that, because these are private companies, they should be allowed to choose who to have as their customers. The other side argues that, because these are vital communication networks, private companies shouldn’t be allowed to ban any individuals.
So creating a regime in which a social media platforms could be designated as a common carrier – whether at the discretion of the platform owner or as a result of criteria laid down in the regime – would not put an end to social media bans. But the imposition of the banning orders would almost certainly be handed to an external agency, as should the rules for what can and can’t be posted on such sites.


In the years since, we’ve learned how these kinds of targeted ads can create political filter bubbles and echo chambers, suspected of dividing people and increasing the circulation of harmful disinformation.
Machine learning algorithms are bad at identifying contextual harms. On the contrary, the way targeting works actually amplifies them. Several audits, for example, have uncovered how Facebook has allowed discriminatory targeting that worsens socioeconomic inequalities.
The root cause of all these issues can be traced to the fact that consumers have a very isolated experience online. We call this a state of “epistemic fragmentation,” where the information available to each individual is limited to what is targeted at them, without the opportunity to compare with others in a shared space like the London Underground.

Ethics is two things. First, ethics refers to well-founded standards of right and wrong that prescribe what humans ought to do, usually in terms of rights, obligations, benefits to society, fairness, or specific virtues. Ethics, for example, refers to those standards that impose the reasonable obligations to refrain from rape, stealing, murder, assault, slander, and fraud. Ethical standards also include those that enjoin virtues of honesty, compassion, and loyalty. And, ethical standards include standards relating to rights, such as the right to life, the right to freedom from injury, and the right to privacy. Such standards are adequate standards of ethics because they are supported by consistent and well-founded reasons.
Secondly, ethics refers to the study and development of one's ethical standards. As mentioned above, feelings, laws, and social norms can deviate from what is ethical. So it is necessary to constantly examine one's standards to ensure that they are reasonable and well-founded. Ethics also means, then, the continuous effort of studying our own moral beliefs and our moral conduct, and striving to ensure that we, and the institutions we help to shape, live up to standards that are reasonable and solidly-based.
Virtue ethics is arguably the oldest ethical theory in the world, with origins in Ancient Greece.
It defines good actions as ones that display embody virtuous character traits, like courage, loyalty, or wisdom. A virtue itself is a disposition to act, think and feel in certain ways. Bad actions display the opposite and are informed by vices, such as cowardice, treachery, and ignorance.
For Aristotle, ethics was a key element of human flourishing because it taught people how to differentiate between virtues and vices. By encouraging examination, more people could live a life dedicated to developing virtues.
It’s one thing to know what’s right, but it’s another to actually do it. How did Aristotle advise us to live our virtues?
By acting as though we already have them.
Excellence as habit
Aristotle explained that both virtues and vices are acquired by repetition. If we routinely overindulge a sweet tooth, we develop a vice — gluttony. If we repeatedly allow others to serve themselves dinner before us, we develop a virtue – selflessness.
Virtue ethics suggests treating our character as a lifelong project, one that has the capacity to truly change who we are. The goal is not to form virtues that mean we act ethically without thinking, but to form virtues that help us see the world clearly and make better judgments as a result.
In a pinch, remember: vices distort, virtues examine.
A quote most of the internet attributes to Aristotle succinctly reads: “We are what we repeatedly do. Excellence, then, is not an act, but a habit”.
Though he didn’t actually say this, it’s a good indication of what virtue ethics stands for. We can thank American philosopher, Will Durant, for the neat summary.

Utilitarianism is a prominent perspective on ethics, one that is well aligned with economics and the free-market outlook that has come to dominate much current thinking about business, management, and economics. Jeremy Bentham is often considered the founder of utilitarianism, though John Stuart Mill (who wrote On Liberty and Utilitarianism) and others promoted it as a guide to what is good. Utilitarianism emphasizes not rules but results. An action (or set of actions) is generally deemed good or right if it maximizes happiness or pleasure throughout society. Originally intended as a guide for legislators charged with seeking the greatest good for society, the utilitarian outlook may also be practiced individually and by corporations.
the utilitarian principle holds that an action is right if and only if the sum of utilities produced by that action is greater than the sum of utilities from any other possible act.
1.	Failing to come up with lots of options that seem reasonable and then choosing the one that has the greatest benefit for the greatest number. Often, a decision maker seizes on one or two alternatives without thinking carefully about other courses of action. If the alternative does more good than harm, the decision maker assumes it’s ethically okay.
2.	Assuming that the greatest good for you or your company is in fact the greatest good for all—that is, looking at situations subjectively or with your own interests primarily in mind.
3.	Underestimating the costs of a certain decision to you or your company. The now-classic Ford Pinto case demonstrates how Ford Motor Company executives drastically underestimated the legal costs of not correcting a feature on their Pinto models that they knew could cause death or injury. General Motors was often taken to task by juries that came to understand that the company would not recall or repair known and dangerous defects because it seemed more profitable not to. In 2010, Toyota learned the same lesson.
4.	Underestimating the cost or harm of a certain decision to someone else or some other group of people.
5.	Favoring short-term benefits, even though the long-term costs are greater.
6.	Assuming that all values can be reduced to money. In comparing the risks to human health or safety against, say, the risks of job or profit losses, cost-benefit analyses will often try to compare apples to oranges and put arbitrary numerical values on human health and safety.

Rules and Duty: Deontology Deontology is an ethical theory that says actions are good or bad according to a clear set of rules. From an ethical perspective, personhood creates a range of rights and obligations because every person has inherent dignity – something that is fundamental to and is held in equal measure by each and every person.
Deontologists require us to follow universal rules we give to ourselves. These rules must be in accordance with reason – in particular, they must be logically consistent and not give rise to contradictions.

It’s worth mentioning that deontology is often seen as being strongly opposed to consequentialism. This is because in emphasising the intention to act in accordance with our duties, deontology believes the consequences of our actions have no ethical relevance at all – a similar sentiment to that captured in the phrase “Let justice be done, though the heavens may fall”.

The appeal of deontology lies in its consistency. By applying ethical duties to all people in all situations the theory is readily applied to most practical situations. By focussing on a person’s intentions, it also places ethics entirely within our control – we can’t always control or predict the outcomes of our actions, but we are in complete control of our intentions.

Others criticise deontology for being inflexible. By ignoring what’s at stake in terms of consequences, some say it misses a serious element of ethical decision-making. De-emphasising consequences has other implications too – can it make us guilty of ‘crimes of omission’? Kant, for example, argued it would be unethical to lie about the location of our friend, even to a person trying to murder them! For many, this seems intuitively false.
Its name comes from the Greek word deon, meaning duty. Actions that align with these rules are ethical, while actions that don’t aren’t. This ethical theory is most closely associated with German philosopher, Immanuel Kant.
In contrast to the utilitarian perspective, the deontological view presented in the writings of Immanuel Kant purports that having a moral intent and following the right rules is a better path to ethical conduct than achieving the right results. A deontologist like Kant is likely to believe that ethical action arises from doing one’s duty and that duties are defined by rational thought.
Kantian ethicists would answer that your chosen course of action should be a universal one—a course of action that would be good for all persons at all times. There are two requirements for a rule of action to be universal: consistency and reversibility. Consider reversibility: if you make a decision as though you didn’t know what role or position you would have after the decision, you would more likely make an impartial one—you would more likely choose a course of action that would be most fair to all concerned, not just you. Again, deontology requires that we put duty first, act rationally, and give moral weight to the inherent equality of all human beings.
Finally, we should note that the well-known Golden Rule, “Do unto others as you would have them do unto you,” emphasizes the easier of the two universalizing requirements: practicing reversibility

Social Justice Theory and Social Contract Theory Social justice theorists worry about “distributive justice”—that is, what is the fair way to distribute goods among a group of people? 
Social contract theories see the relationship of power between state and citizen as a consensual exchange. It is legitimate only if given freely to the state by its citizens and explains why the state has duties to its citizens and vice versa.
if the social contract is a real contract – just like your employment contract – people could be free not to accept the terms. If a person didn’t agree they should give some of their income to the state they should be able to decline to pay tax and as a result, opt out of state-funded hospitals, education, and all the rest. 
Like other contracts, withdrawing comes with penalties – so citizens who decide to stop paying taxes may still be subject to punishment. 
Other problems arise when the social contract is looked at through a feminist perspective. Historically, social contract theories, like the ones proposed by Hobbes and Locke, say that (legitimate) state authority comes from the consent of free and equal citizens. 
In Pateman’s words the social contract is first and foremost a ‘sexual contract’ that keeps women in a subordinate role. The structural subordination of women that props up the classic social contract theory is inherently unjust. 
The inherent injustice of social contract theory is further highlighted by those critics that believe individual citizens are forced to opt in to the social contract. Instead of being given a choice, they are just lumped together in a political system which they, as individuals, have little chance to control.  

Even the most dedicated free-market capitalist will often admit the need for some government and some forms of welfare—Social Security, Medicare, assistance to flood-stricken areas, help for AIDs patients—along with some public goods (such as defense, education, highways, parks, and support of key industries affecting national security).
People who do not see the need for public goods (including laws, court systems, and the government goods and services just cited) often question why there needs to be a government at all. One response might be, “Without government, there would be no corporations.” Thomas Hobbes believed that people in a “state of nature” would rationally choose to have some form of government. He called this the social contract, where people give up certain rights to government in exchange for security and common benefits.
1.	If you have a right of free expression, the government has a duty to respect that right but can put reasonable limits on it. For example, you can legally say whatever you want about the US president, but you can’t get away with threatening the president’s life. Even if your criticisms are strong and insistent, you have the right (and our government has the duty to protect your right) to speak freely. In Singapore during the 1990s, even indirect criticisms—mere hints—of the political leadership were enough to land you in jail or at least silence you with a libel suit.
2.	Rights and duties exist not only between people and their governments but also between individuals. Your right to be free from physical assault is protected by the law in most states, and when someone walks up to you and punches you in the nose, your rights—as set forth in the positive law of your state—have been violated. Thus other people have a duty to respect your rights and to not punch you in the nose.
3.	Your right in legal terms is only as good as your society’s willingness to provide legal remedies through the courts and political institutions of society.
A distinction between basic rights and nonbasic rights may also be important. Basic rights may include such fundamental elements as food, water, shelter, and physical safety. Another distinction is between positive rights (the right to bear arms, the right to vote, the right of privacy) and negative rights (the right to be free from unreasonable searches and seizures, the right to be free of cruel or unusual punishments). Yet another is between economic or social rights (adequate food, work, and environment) and political or civic rights (the right to vote, the right to equal protection of the laws, the right to due process).


Consequentialism is a theory that says whether something is good or bad depends on its outcomes.
An action that brings about more benefit than harm is good, while an action that causes more harm than benefit is not. The most famous version of this theory is utilitarianism.
Although there are references to this idea in the works of ancient philosopher Epicurus, it’s closely associated with English philosopher Jeremy Bentham.
Bentham’s theory of utilitarianism focussed on which actions were most likely to make people happy. If happiness was the experience of pleasure without pain, the most ethical actions were ones that caused the most possible happiness and the least possible pain.
He even developed a calculator to work out which actions were better or worse – the ‘felicific calculus’. Because it counted every person’s pleasure or pain as the same, regardless of age, wealth, race, etc. utilitarianism could be seen as a radically egalitarian philosophy.
Consequentialism is an attractive ethical approach because it provides clear and practical guidance – at least in situations where outcomes are easy to predict. The theory is also impartial. By asking us to maximise benefit for the largest number of people (or, for Peter Singer and other preference utilitarians, creatures who have preferences), we set aside our personal biases and self-interest to benefit others.
One problem with the theory is that it can be hard to measure different benefits to decide which one is morally preferable. Is it better to give my money to charity or spend it studying medicine so I can save lives? Many forms of consequentialism have been proposed that attempt to deal with the issue of comparing moral value.
The other concern people express is the tendency of consequentialism to use ‘ends justify the means’ logic. If all we are concerned with is getting good outcomes, this can seem to justify harming some people in order to benefit others. Is it ethical to allow some people to suffer so more people can live well?


Virtue theory, or virtue ethics, has received increasing attention over the past twenty years, particularly in contrast to utilitarian and deontological approaches to ethics. Virtue theory emphasizes the value of virtuous qualities rather than formal rules or useful results. Aristotle is often recognized as the first philosopher to advocate the ethical value of certain qualities, or virtues, in a person’s character. 
Aristotle believed that all activity was aimed at some goal or perceived good and that there must be some ranking that we do among those goals or goods. Happiness may be our ultimate goal, but what does that mean, exactly? Aristotle rejected wealth, pleasure, and fame and embraced reason as the distinguishing feature of humans, as opposed to other species. And since a human is a reasoning animal, happiness must be associated with reason. Thus happiness is living according to the active (rather than passive) use of reason. The use of reason leads to excellence, and so happiness can be defined as the active, rational pursuit of personal excellence, or virtue.
Aristotle named fourteen virtues: (1) courage, particularly in battle; (2) temperance, or moderation in eating and drinking; (3) liberality, or spending money well; (4) magnificence, or living well; (5) pride, or taking pleasure in accomplishments and stature; (6) high-mindedness, or concern with the noble rather than the petty; (7) unnamed virtue, which is halfway between ambition and total lack of effort; (8) gentleness, or concern for others; (9) truthfulness; (10) wit, or pleasure in group discussions; (11) friendliness, or pleasure in personal conduct; (12) modesty, or pleasure in personal conduct; (13) righteous indignation, or getting angry at the right things and in the right amounts; and (14) justice.
Among the virtues, are any especially important? Studies from the Josephson Institute of Ethics in Marina del Rey, California, have identified six core values in our society, values that almost everyone agrees are important to them. When asked what values people hold dear, what values they wish to be known by, and what values they wish others would exhibit in their actions, six values consistently turn up: (1) trustworthiness, (2) respect, (3) responsibility, (4) fairness, (5) caring, and (6) citizenship.


 Instead, virtue ethicists advocate the cultivation of wisdom and character that people can use to internalize basic ethical principles from which they can determine the ethical course of action in particular situations. Virtue ethicists tend to see ethical principles as being inherent in the world and as being discoverable by means of rational reflection and disciplined living. 

What unites the various forms of virtue ethics is the focus on moral education to cultivate moral wisdom, discernment, and character in the belief that ethical virtue will manifest in ethical actions.

Eudaimonia is not momentary pleasure but enduring contentment—not just a good day but a good life. Human flourishing means acting in ways that cause your essential human nature to achieve its most excellent form of expression. Aristotle held that a good life of lasting contentment can be gained only by a life of virtue—a life lived with both phrónesis, or “practical wisdom,” and aretē, or “excellence.” Aristotle defines human good as the activity of the soul in accordance with virtue, and wrote in the Nicomachean Ethics that

Too Little	Mean (Virtue)	Too Much
Cowardice	Bravery	Foolhardiness
Stinginess	Generosity	Profligacy
Self-ridicule	Confidence	Boastfulness
Apathy	Calmness	Short-Temperedness
Virtues such as temperance, courage, and truthfulness become increasingly a part of our actions the more we intend to do them and the more we practice doing them. The truly virtuous person:
•	Knows what she or he is doing.
•	Chooses a virtuous act for its own sake.
•	Chooses as a result of a settled moral state.
•	Chooses gladly and easily.
OBJECTIONS TO VIRTUE ETHICS
There are two main objections to virtue ethics as an ethical system: its vagueness and its relativism.
First, virtue ethics is too vague and subjective, and does not produce explicit rules for moral conduct that can tell us how to act in specific circumstances. When facing ethical dilemmas, we feel better if we have a clear answer about what to do. Virtue ethics offers general ideals rather than definitive commands. 
Second, there are different cultural definitions of human flourishing and virtue. All human cultures have ethical values, but values vary across cultures. So how can we decide which set of virtues is right? Even within a culture, two people will have different views about what the virtues are, and when and how they apply. Because virtue ethics gives us no specific commands for how to act, each person is left to himself or herself to decide how to act. Virtue ethics is too relative to be a helpful ethical theory.
Ethical relativism is a concern. If ethics means anything, it has to have some objective basis and cannot be left entirely up to arbitrary whim. Virtue ethicists are aware of this danger and would respond to it that virtue ethics is based on objective realities of the world and human nature. The virtues are manifestations of how things are, or should be, outside of cultural or individual subjectivity. Different cultures differ on how ethical virtues should be applied, but every culture values fundamental virtues such as honesty, benevolence, courage, and justice. Differences in how cultures apply virtues may reflect objective differences in their circumstances. When we interact with another culture, those differences do need to be dealt with, but saying our culture is completely right and the other culture wrong is not a helpful approach. Individuals similarly face the burden of needing to determine how best to apply the virtues, and needing to deal with conflicts with others over how they think is best to apply the virtues. But is this not similar to the decisions we have to make in all aspects of our lives?

